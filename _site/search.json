[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "BLOG",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nParametric Survival Analysis: UN Peacekeeping Missions\n\n\n\n\n\n\n\nR\n\n\nPython\n\n\nsurvival-analysis\n\n\nwar\n\n\npeacekeeping\n\n\n\n\n\n\n\n\n\n\n\nAug 8, 2023\n\n\n15 min\n\n\n\n\n\n\n  \n\n\n\n\nProxy Wars - Scraping data from Wikipedia\n\n\n\n\n\n\n\nscraping\n\n\nR\n\n\ncombat\n\n\n\n\nScrape Wikipedia for proxy war data\n\n\n\n\n\n\nAug 8, 2023\n\n\n5 min\n\n\n\n\n\n\n  \n\n\n\n\nInsurgent (Pairwise) Networks\n\n\n\n\n\n\n\nnetwork analysis\n\n\nR\n\n\ncombat\n\n\n\n\nConflict makes for strange bedfellows\n\n\n\n\n\n\nAug 22, 2022\n\n\n13 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bad ideas executed with vigor",
    "section": "",
    "text": "Welcome to my data science-sandbox. I come here to play and explore data, quantitative methods, and the intersections among society, the arts, and conflict. I’ve always been intrigued by the complex dynamics and passions of society, and this blog is a platform for exploring all that through the lens of data science.\nI’m a former professional dancer turned U.S. Army Reservist turned data scientist. My life has been a nutty blend of “So You Think You Can Dance”, “Band of Brothers” and “Money Ball.”\nLet me be clear: I make no claims that what I’m doing here would pass academic muster. This is more like stumbling into a private studio or workshop. I do my best to be thoughtful and thorough, but you won’t find any peer-reviewed publications here (though let’s be honest, that process has taking some heat in recent years anyway).\nSo poke around. I hope you find something interesting. If you find it useful, steal it. If you have comments or suggestions, I would love to hear them.\nThanks for being here!"
  },
  {
    "objectID": "posts/new/new_post.html",
    "href": "posts/new/new_post.html",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %>% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod <- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds <- dat %>% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit > 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %>% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]\n\n\n\n\n\n\n\n\ngeom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\n\n\n\n\n\n\nggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "posts/new/new_post.html#subheading",
    "href": "posts/new/new_post.html#subheading",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod &lt;- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds &lt;- dat %&gt;% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit &gt; 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]"
  },
  {
    "objectID": "posts/new/new_post.html#columns",
    "href": "posts/new/new_post.html#columns",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "geom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)"
  },
  {
    "objectID": "posts/new/new_post.html#margin-captions",
    "href": "posts/new/new_post.html#margin-captions",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "ggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/proxy-wiki-scrape/index.html",
    "href": "posts/proxy-wiki-scrape/index.html",
    "title": "Proxy Wars - Wiki Scrape",
    "section": "",
    "text": "Image source: Virginia Tech Publishing"
  },
  {
    "objectID": "posts/proxy-wiki-scrape/index.html#proxy-wars",
    "href": "posts/proxy-wiki-scrape/index.html#proxy-wars",
    "title": "Proxy Wars - Wiki Scrape",
    "section": "Proxy wars",
    "text": "Proxy wars\nViolence, conflict, and proxy warfare – all on a blissful, dreamy Sunday afternoon. Actually, I was listening to an NPR discussion on an afternoon drive that referenced the work of the Proxy War Project out of Virginia Tech. As a data geek, the next obvious question is: Gee, where can I find data on that?\nWhat does the general public think of regarding proxy warfare? Is it a rag tag group of thugs funded by a dark agency and left to run around the forest? Or maybe proxy wars are a relic of the cold war? To the contrary, according to War on the Rocks (a super cool site on all things war and conflict), “[e]vents of the last decade suggest the increasing salience of such conflicts.” The blog goes on to say that “[p]roxy wars are poised to be a…significant factor in the evolving strategic environment.”\nSo, as soon as I got home, I jumped online for a quick search for some data. The first thing I found was the Wikipedia page. It most certainly is not the most comprehensive data, but it has a nice feature: A helpful Wiki contributor created a typology of proxy wars. I decided to scrape it to started some initial exploration.\nI’m not intending for this to be a deep dive into coding nor proxy war dynamics. This is just a quick and dirty scrape of Wikipedia data to get a sense of what’s going."
  },
  {
    "objectID": "posts/proxy-wiki-scrape/index.html#scraping-and-cleaning-wikipedia-data",
    "href": "posts/proxy-wiki-scrape/index.html#scraping-and-cleaning-wikipedia-data",
    "title": "Proxy Wars - Wiki Scrape",
    "section": "Scraping and Cleaning Wikipedia Data",
    "text": "Scraping and Cleaning Wikipedia Data\n\n\nCode\n# libraries\nlibrary(rvest)\nlibrary(tidyverse)\nlibrary(kableExtra)\nsource(\"my_gg_theme.R\")\n\n# Scrape the tables from the page\nproxy_tables &lt;- \n  read_html('https://en.wikipedia.org/wiki/List_of_proxy_wars') %&gt;%\n  html_table(fill = TRUE) %&gt;% \n  # set names based on Wikipedia names\n  set_names(\n    c(\n      'Caveat',\n      'Series', \n      'Pre-World War I proxy wars', \n      'Inter-war period proxy wars',\n      'Cold War proxy wars',\n      'Modern proxy wars',\n      'Ongoing proxy wars'\n    )) \n\n\nThe Wikipedia page displays the following caveat:\n\nThis article or section appears to be slanted towards recent events. Please try to keep recent events in historical perspective and add more content related to non-recent events. (October 2022)\n\nWikipedia spread the data across a number of tables. To prep the data for plotting, I put them into one big data frame and did some minor cleaning. In particular, the dates were a little jenky. The resulting data looks like:\n\n\nCode\n# data cleaning\nproxy_data_df &lt;- \n  # drop unneeded data\n  proxy_tables[-c(1,2)] %&gt;% \n  map2_df(\n    names(proxy_tables[-c(1,2)]),\n    ~mutate(.x, war_type = .y)) %&gt;% \n  janitor::clean_names() %&gt;% \n  separate(\n    dates, \n    into = c('start_year', 'end_year'), \n    sep = \"–\") %&gt;%\n  mutate(across(\n    start_year:end_year,\n    ~ str_extract(.x, '[0-9]{4}') %&gt;% \n    as.numeric(.x))) %&gt;% \n  mutate(across(\n    c(war, combatant_1, combatant_1, result),\n    ~ str_remove(., \"\\\\[.*\\\\]$\")))\n\nproxy_data_df %&gt;% \n  slice_head(n = 5) %&gt;% \n  knitr::kable() %&gt;%\n  kable_styling(font_size = 7)\n\n\n\n\n\nwar\nstart_year\nend_year\ncombatant_1\ncombatant_2\nresult\nwar_type\n\n\n\n\nEgyptian–Ottoman War\n1839\n1841\nEgypt-aligned powers: Egypt France Spain\nAllied powers: British Empire Austrian Empire Russian Empire Kingdom of Prussia Ottoman Empire\nCompromise\nPre-World War I proxy wars\n\n\nUruguayan Civil War\n1839\n1851\nColorados Unitarian Party Empire of Brazil Italian Legion France Great Britain\nBlancos Argentine Confederation\nColorado victory\nPre-World War I proxy wars\n\n\nMahdist War\n1881\n1899\nBritish Empire  Canada Khedivate of Egypt Belgium  Congo Free State Ethiopian Empire  Italy Supported by: Emirate of Jabal Shammar\nMahdist Sudan Supported by: Ottoman Empire Russian Empire France\nBritish-Egyptian-Italian victory\nPre-World War I proxy wars\n\n\nFirst Samoan Civil War\n1886\n1894\nTamasese German Empire\nMata'afans Supported by: United States\nStalemate\nPre-World War I proxy wars\n\n\nSecond Samoan Civil War\n1898\n1899\nMata'afans German Empire\nSamoa United Kingdom United States\nStalemate\nPre-World War I proxy wars"
  },
  {
    "objectID": "posts/proxy-wiki-scrape/index.html#plotting-war-duration",
    "href": "posts/proxy-wiki-scrape/index.html#plotting-war-duration",
    "title": "Proxy Wars - Wiki Scrape",
    "section": "Plotting war duration",
    "text": "Plotting war duration\nTo avoid rewriting a bunch of code, let’s create a little function to select the war-type of choice and plot the data. (Note, the plotting code was a little long and distracting, so I pushed some of it to a source script.)\n\n\nCode\n# a function to select war type and plot\nwar_plot &lt;- function(df, type) {\n  \n  df %&gt;% \n    filter(\n      war_type == type\n    ) %&gt;% \n    ggplot(aes(\n      x = fct_reorder(war, -start_year),\n      y = start_year)) +\n    geom_segment(aes(\n      xend = war, \n      yend = end_year), \n      color = \"cadetblue\",\n      alpha = 0.75) +\n    # year start\n    geom_point(color = \"orange\", # #E69F00\n               size = 3,\n               alpha = 0.8) +\n    # year end\n    geom_point(aes(\n      y = end_year), \n      color = \"cadetblue\", \n      size = 3,\n      alpha = 0.8) +  \n    \n    coord_flip() +\n    labs(\n      x = \"\", \n      y = \"\",\n      title = type\n      ) +\n    # a sourced function for some trivial formatting \n    quick_gg_theme()\n}\n\n\n\n\nCode\nwar_plot(proxy_data_df, \"Pre-World War I proxy wars\")\nwar_plot(proxy_data_df, 'Inter-war period proxy wars')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nwar_plot(proxy_data_df, 'Modern proxy wars')\nwar_plot(proxy_data_df, 'Ongoing proxy wars')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nwar_plot(proxy_data_df, 'Cold War proxy wars')"
  },
  {
    "objectID": "posts/proxy-wiki-scrape/index.html#wrap-up",
    "href": "posts/proxy-wiki-scrape/index.html#wrap-up",
    "title": "Proxy Wars - Wiki Scrape",
    "section": "Wrap up",
    "text": "Wrap up\nFirst, that’s a lot o’ proxy wars. Of course, there’s clearly a few problems with the data. Some dates are missing. And I’m suspicious about the ongoing proxy wars. Are they all really still ongoing?\nThe Cold War was fertile ground for proxy wars. I guess it makes sense, right? Cold wars are characterized by indirect conflict, working through proxies, pawns, and agents of mayhem.\nGiven that proxy wars are frequently a means for “agents” to have deniability regarding the havoc they are wrecking, there is likely a large number of unreported/undiscovered agent-proxy relationships.\nIt might be interesting to parse the text-based columns and see which actors are most frequently leveraging proxies, and in what parts of the world…another day…"
  },
  {
    "objectID": "posts/series1/new_post/post.html",
    "href": "posts/series1/new_post/post.html",
    "title": "Dummy post in series",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod &lt;- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds &lt;- dat %&gt;% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit &gt; 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]\n\n\n\n\n\n\n\n\ngeom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\n\n\n\n\n\n\nggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "posts/series1/new_post/post.html#merriweather",
    "href": "posts/series1/new_post/post.html#merriweather",
    "title": "Dummy post in series",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod &lt;- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds &lt;- dat %&gt;% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit &gt; 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]"
  },
  {
    "objectID": "posts/series1/new_post/post.html#columns",
    "href": "posts/series1/new_post/post.html#columns",
    "title": "Dummy post in series",
    "section": "",
    "text": "geom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)"
  },
  {
    "objectID": "posts/series1/new_post/post.html#margin-captions",
    "href": "posts/series1/new_post/post.html#margin-captions",
    "title": "Dummy post in series",
    "section": "",
    "text": "ggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/pairwise_network/network_pairwise.html",
    "href": "posts/pairwise_network/network_pairwise.html",
    "title": "Insurgent (Pairwise) Networks",
    "section": "",
    "text": "During the height of the Syrian civil war, many of us watching from afar were puzzled when “moderate” insurgent groups would jump into bed (or alliances) with hardliners or jihadists. The Syrian conflict had hundreds, maybe thousands, of armed groups forming various kinds of alliances, then divorcing only to reconcile again.\nA lot is made of the role of ideology when armchair commanders (like myself) comment as these disasters play out. On the other hand, alliances could be a pragmatic choice. By aggregating combat power, armed groups might increase their chances of survival—even if only to turn on each other at a later stage.\nIn fact, I recently read a compelling argument on this topic: “Alliance Formation in Civil Wars” by Fotini Christia.1 In this book, Christia states: “It would be natural to suppose that warring groups form alliances based on shared identity considerations—such as Christian groups allying with Christian groups or Muslim groups with their fellow co-religionists—but this is not what we see.”\nSo, with that motivation, I decided to explore what we could find among Syrian armed groups. When coalitions of Syrian armed groups engaged in battles, they frequently partnered with several groups. So, my question was: would groups tolerate fighting alongside other groups that are ideological enemies? So, I’m focusing on pairwise relationships, even when there are many groups in the alliance.\nCode\nlibrary(tidyverse)\nlibrary(ggraph)\nlibrary(tidygraph)\nlibrary(rsvg)\nlibrary(cowplot)\nlibrary(ggtext)\nlibrary(igraph)\nlibrary(devtools)"
  },
  {
    "objectID": "posts/pairwise_network/network_pairwise.html#data",
    "href": "posts/pairwise_network/network_pairwise.html#data",
    "title": "Insurgent (Pairwise) Networks",
    "section": "Data",
    "text": "Data\n\n\n\n\n\n\nA love affair with ACLED data!\n\n\n\nI came across the Armed Conflict Location & Event Data Project(ACLED) a few years ago. What an amazing resource. ACLED is a disaggregated data collection, analysis, and crisis mapping project. The ACLED team collects real time and historical data on political violence and protest events in nearly 100 countries. In short, it’s awesome.2\n\n\nACLED data is robust, with many columns and over many years. In this dataset, actor (along with assoc_actor_1 acts in some (usually bad) way on actor2. So, I’m only concerned with the actor1 and assoc_actor_1 columns. Let’s just take a quick peak:\n\n\nCode\nread_csv(\"df_acled_syr_2017_2021.csv\") |&gt; \n  select(year, event_date, event_type, actor1, assoc_actor_1) |&gt; \n  filter(!is.na(assoc_actor_1)) |&gt;\n  slice_head(n = 5) |&gt; \n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\nyear\nevent_date\nevent_type\nactor1\nassoc_actor_1\n\n\n\n\n2021\n2021-02-05\nBattles\nOperation Peace Spring\nJWS: Syrian National Army; Military Forces of Turkey (2016-)\n\n\n2021\n2021-02-05\nBattles\nOpposition Rebels (Syria)\nMilitary Forces of Turkey (2016-)\n\n\n2021\n2021-02-05\nExplosions/Remote violence\nAl Fath Al Mubeen Operation Room\nOpposition Rebels (Syria)\n\n\n2021\n2021-02-05\nBattles\nMilitary Forces of Syria (2000-)\nMilitia (Pro-Government)\n\n\n2021\n2021-02-04\nExplosions/Remote violence\nOpposition Rebels (Syria)\nMilitary Forces of Turkey (2016-)\n\n\n\n\n\n \nI need select the columns of interest and then filter down to battle related events (filtering out Protests, Riots, and Violence against civilians)\n\n\nCode\ndf_acled_syr &lt;- \n  read_csv(\"df_acled_syr_2017_2021.csv\") |&gt; \n  filter(year %in% 2017:2019,\n         event_type %in% c(\"Explosions/Remote violence\",\n                           \"Battles\",\n                           \"Strategic developments\")) |&gt; \n  select(actor1, assoc_actor_1) |&gt; \n  mutate(actor1 = str_squish(actor1),\n         assoc_actor_1 = str_squish(assoc_actor_1)) \n\n\n \nHere’s the difficult part. The reduced ACLED data looks akin to this:\n\n\nCode\n(test &lt;- tibble::tibble(\n  actor1 = c(\"A\", \"A\", \"B\"),\n  assoc_actor_1 = c(\"B\", \"B; C\", \"C; D; E\"))) |&gt; \n  knitr::kable()\n\n\n\n\n\nactor1\nassoc_actor_1\n\n\n\n\nA\nB\n\n\nA\nB; C\n\n\nB\nC; D; E\n\n\n\n\n\n \nFor what I’m interested in, I need to get the pairwise combinations. So, I need to work out and test the code to accomplish this. A huge thanks to Dusty Turner.3 In fact, this chunk is largely thanks to his generosity.\n\n\nCode\n#| # Separate assoc actors to get all pairwise partnerships'\ndf &lt;- \n  test |&gt; \n  # use only actors with multiple associated actors\n  filter(str_detect(assoc_actor_1, \";\")) |&gt;\n  separate_rows(assoc_actor_1, sep = \";\") |&gt;\n  mutate(assoc_actor_1 = str_squish(assoc_actor_1)) |&gt; \n  pivot_longer(actor1:assoc_actor_1) |&gt; \n  select(value) |&gt; \n  distinct(value) |&gt; \n  mutate(value2 = value) |&gt; \n  expand(value, value2) |&gt; \n  filter(value !=value2) |&gt; \n  mutate(helper = str_c(value,value2)) |&gt; \n  rowwise() |&gt; \n  mutate(helper = str_c(str_sort(unlist(str_split(helper, \"\"))),collapse = \"\")) |&gt; \n  distinct(helper,.keep_all = T) |&gt; \n  select(-helper) |&gt; \n  rename(actor1 = value, assoc_actor_1 = value2)\n\n# bind back with actors that don't have multiple assoc actors\ntest |&gt; \n  filter(!str_detect(assoc_actor_1, \";\")) |&gt;\n  bind_rows(df) |&gt; \n  knitr::kable()\n\n\n\n\n\nactor1\nassoc_actor_1\n\n\n\n\nA\nB\n\n\nA\nB\n\n\nA\nC\n\n\nA\nD\n\n\nA\nE\n\n\nB\nC\n\n\nB\nD\n\n\nB\nE\n\n\nC\nD\n\n\nC\nE\n\n\nD\nE\n\n\n\n\n\n \nThat looks good! Let’s apply it to the ACLED data.\n\n\nCode\n# Separate assoc actors to get all pairwise partnerships'\ndf_separate &lt;- \n  df_acled_syr |&gt; \n  # use only actors with multiple associated actors\n  filter(str_detect(assoc_actor_1, \";\")) |&gt;\n  separate_rows(assoc_actor_1, sep = \";\") |&gt;\n  mutate(assoc_actor_1 = str_squish(assoc_actor_1)) |&gt; \n  pivot_longer(actor1:assoc_actor_1) |&gt; \n  select(value) |&gt; \n  distinct(value) |&gt; \n  mutate(value2 = value) |&gt; \n  expand(value, value2) |&gt; \n  filter(value !=value2) |&gt; \n  mutate(helper = str_c(value,value2)) |&gt; \n  rowwise() |&gt; \n  mutate(helper = str_c(str_sort(unlist(str_split(helper, \"\"))),collapse = \"\")) |&gt; \n  distinct(helper,.keep_all = T) |&gt; \n  select(-helper) |&gt; \n  rename(actor1 = value, assoc_actor_1 = value2)\n\n# bind back with actors that don't have multiple assoc actors\nreshaped_df &lt;- df_acled_syr |&gt; \n  filter(!str_detect(assoc_actor_1, \";\")) |&gt;\n  bind_rows(df_separate)\n\n\n \nOk, I have to confess. This next part stumped me and took forever. First, a huge shout out to Wikipedia contributors. There are soooo many actors in the dataset. I spend much more time than intended trying to consolidate them, constantly referencing Wikipedia to figure out what’s going on.\nSecond, I needed to clean and consolidate the actors, and then remove the non-opposition groups as well as the non-armed-opposition groups. I tried several ways to make happen much more parsimoniously with sapply and purrr::map and a two-column lookup table, but it beat me. If you have suggestions, I’m eager to hear them.\n\n\nCode\n# create a lookup table for groups to remove\nremove_groups &lt;-\n  c(\"Military Forces\", \"Police Forces\", \n    \"Operations Room\", \"Opposition Rebels\", \n    \"Alliance/Named Operation\", \"Tribal\", \n    \"Military Council\", \"Communal Militias\", \n    \"Civilians\", \"SDF\", \"Islamic State\")\n\ndf_acled_actors &lt;- \n  reshaped_df |&gt;\n  mutate(\n    across(\n      actor1:assoc_actor_1,\n      ~ case_when(\n        str_detect(.x, \"Military Forces|Government|Allied Syrian\") ~ \"Military Forces\",\n        str_detect(.x, \"Unidentified Armed|Opposition Rebels|Islamist|Sunni Muslim|JSH\") ~ \"Opposition Rebels\",\n        str_detect(.x, \"Police Forces\") ~ \"Police Forces\",\n        str_detect(.x, \"HXP|QSD|YPG|YPJ|Liberation Army of Afrin|Menbij Internal|Asayish|Syriac\") ~ \"SDF\",\n        str_detect(.x, \"HTS|JFS|Jabhat Fateh al Sham\") ~ \"Hayat Tahrir al Sham\",\n        str_detect(.x, \"Hamza Division|Hamza Brigade\") ~ \"Hamza Division\", \n        str_detect(.x, \"AAS:\") ~ \"Ahrar al Sham\", \n        str_detect(.x, \"Al Sham Corps|Al Sham Division\") ~ \"Faylaq al Sham\",\n        str_detect(.x, \"HNDZ\") ~ \"Nour al Din al Zinki\",\n        str_detect(.x, \"Sharqiya Army\") ~ \"Jaysh Sharqiya\",\n        str_detect(.x, \"Liwa al Aqsa\") ~ \"Jund al Aqsa\",\n        str_detect(.x, \"FaR:\") ~ \"Faylaq al Rahman\",\n        str_detect(.x, \"JaS:\") ~ \"Levant Front\",\n        str_detect(.x, \"Sultan Suleiman Shah\") ~ \"Sultan Suleiman Shah\",\n        str_detect(.x, \"Operations Room\") ~ \"Operations Room\",\n        str_detect(.x, \"Operation Room\") ~ \"Operations Room\",\n        str_detect(.x, \"Wa Harredh al Moa'mineen\") ~ \"Operations Room\",\n        str_detect(.x, \"JWS:|JTW:|JTS:|Euphrates Shield|Peace Spring\") ~ \"Alliance/Named Operation\",\n        str_detect(.x, \"Islamic State\") ~ \"Islamic State\",\n        str_detect(.x, \"Tribal\") ~ \"Tribal\",\n        str_detect(.x, \"Military Council\") ~ \"Military Council\",\n        str_detect(.x, \"TIP:\") ~ \"Turkistan Islamic Party\",\n        str_detect(.x, \"Communal\") ~ \"Communal Militias\",\n        str_detect(.x, \"Kurdish Ethnic\") ~ \"Kurdish Ethnic Militia\",\n        str_detect(.x, \"JaT:\") ~ \"Army of the Revolutionaries\",\n        str_detect(.x, \"Sultan Murad\") ~ \"Sultan Murad\",\n        str_detect(.x, \"Ansar al Din\") ~ \"Ansar al Din\",\n        str_detect(.x, \"JOS:\") ~ \"Lions of the East\",\n        str_detect(.x, \"LAS\") ~ \"Northern Storm Brigade\",\n        str_detect(.x, \"Civilians|Protesters|Rioters|Aid Workers|Women|Farmers|Refugees|Prisoners|Journalists|\") ~ \"Civilians\",\n        TRUE ~ .x\n      ))) |&gt;\n  \n  # remove civilans, state forces or unidentified groups\n  filter(!actor1 %in% remove_groups,\n         !assoc_actor_1 %in% remove_groups,\n         actor1 != assoc_actor_1) |&gt; \n  \n  # Get the top/most groups by number of operations\n  mutate(actor1 = fct_lump(actor1, 10),\n         assoc_actor_1 = fct_lump(assoc_actor_1, 15)) |&gt; \n  filter(actor1 != \"Other\",\n         assoc_actor_1 != \"Other\")\n\n\n \nLet’s check out what the numbers look like for the top 10 most operationally-active groups. How many joint (aka partnered) operations does each group conduct - measured as a percentage of overall joint operations?\n\n\nCode\nlibrary(DT)\ndatatable(df_acled_actors %&gt;% \n  pivot_longer(cols = actor1:assoc_actor_1,\n               names_to = \"cols\",\n               values_to = \"Name\") %&gt;%\n  group_by(Name) %&gt;% \n  summarize(`Partnered Ops` = n()) %&gt;% \n  mutate(Percent = round(`Partnered Ops`/sum(`Partnered Ops`),2),\n         Percent = scales::percent(Percent)) %&gt;% \n  ungroup() %&gt;% \n  arrange(desc(`Partnered Ops`))) \n\n\n\n\n\n\n\n \nClearly, we expect Hayat Tahrir al-Sham to be a prominent player.\nNow to prep the data for graphing…\n\n\nCode\n# create nodes with count of times each actor appears in dataset\ndf_nodes &lt;- \n  df_acled_actors |&gt; \n  pivot_longer(cols = actor1:assoc_actor_1,\n               names_to = \"cols\",\n               values_to = \"Name\") |&gt; \n  group_by(Name) |&gt; \n  summarize(count = n()) |&gt; \n  ungroup() |&gt; \n  #mutate(countG = cut(count, breaks = c(-Inf, 21, 24, 43, Inf))) |&gt; \n  mutate(countG = case_when(\n    count &lt; 21 ~ \"Least\",\n    count &lt; 25 ~ \"Less\",\n    count &lt; 44 ~ \"More\",\n    TRUE ~ \"Most\"\n  ))\n\n# from original df, weight is the count of how often the two actors work together\n# igraph looks for \"from\", \"to\", and \"weight\"\ndf_edges &lt;- \n  df_acled_actors |&gt;\n  count(actor1,assoc_actor_1) |&gt; \n  rename(weight = n,\n         from = actor1,\n         to = assoc_actor_1)\n\ngraph &lt;- \n  graph_from_data_frame(\n  df_edges, \n  vertices = df_nodes)\n\n\nAnd at last, let’s generate a pairwise network plot. Let’s see who partnered with whom.\n\n\nCode\ngraphed &lt;-\n  graph |&gt; \n  ggraph(layout = 'linear', \n         circular = TRUE) +\n  ggraph::geom_edge_arc(\n    aes(alpha = weight),\n    width = 1,\n    show.legend = FALSE,\n    color = \"grey20\"\n  ) +\n  ggraph::geom_node_point(aes(color = countG)) +\n  ggraph::geom_node_label(\n    aes(label = name, \n        color = countG),\n    alpha = .75,\n    label.size = NA,\n    fill = \"#F3F3F3\", \n    size = 3,\n    repel = F,\n    fontface = \"bold\"\n  ) +\n  labs(\n    title = \"Syrian Opposition: Never go it alone!\",\n    subtitle = \"&lt;b&gt;Bolder lines&lt;/b&gt; indicate more &lt;i&gt;joint&lt;/i&gt; combat operations with that partner.\n           &lt;br&gt;Colors indicate frequency of &lt;i&gt;total&lt;/i&gt; combat operations:\n           &lt;br&gt;&lt;b style='color:black'&gt; Most Frequent&lt;/b&gt;,\n           &lt;b style='color:#450D54'&gt; More Frequent&lt;/b&gt;,\n           &lt;b style='color:#557C9B'&gt; Less Frequent&lt;/b&gt;, and \n           &lt;b style='color:#94B147'&gt;Least Frequent&lt;/b&gt;\",\n    caption = \"Data:  &lt;b&gt;'ACLED Event Data 2017-2020'&lt;/b&gt; (acleddata.com)&lt;br&gt; Visualisation by &lt;b&gt;Michael Davies&lt;/b&gt;\"\n  ) +\n  theme_void() +\n  theme(\n    # margins: top, right, bottom, and left\n    plot.margin = margin(0.7, 0.7, 0.7, 0.7, \"cm\"),\n    plot.title = element_text(size = 20, color = \"grey30\", face = \"bold\"),\n    plot.title.position = 'plot',\n    plot.subtitle = element_markdown(lineheight = 1.2),\n    plot.caption = element_markdown(size = 8),\n    plot.caption.position = 'plot',\n    plot.background = element_rect(color = NA, fill = NA),\n    legend.position = \"none\",\n  ) +\n  scale_color_manual(values = c(\"#94B147\", \"#557C9B\", \"#450D54\", \"black\")) +\n  coord_fixed(ratio = 0.6, clip = \"off\")\n\n\nlibrary(magick)\nimg &lt;- \n  image_read(\"jihadi.PNG\") |&gt;\n  image_resize(\"570x380\") |&gt;\n  image_transparent(\"grey\", fuzz = 35)\n\nggdraw() + \n  draw_plot(\n    ggplot() + \n      theme_void() + \n      theme(\n        plot.background = element_rect(color = NA, fill = \"#F3F3F3\") \n      )) +\n  draw_image(interpolate = F, \n             img, \n             scale = .35, \n             x = 0, \n             y = 0) +\n  draw_plot(graphed) \n\n\n\n\n\nAhhh the tangled web they weave. I know I’ve been mixing metaphors.\nI supposed I should have used the colors to signify ideology so that we can see if ideology and parnterships “travel well together.” However, I became interested in how the frequency of operations and partnership might reflect battlefield success. For instance, Hayat Tahrir al-Sham, by all accounts, rose to be the most dominant opposition group. This is reflected in the fact that they conducted the most operations overall. Notably, however, they seldom engaged in an operation on their own. They engaged in the most frequent “joint operations” - despite being consider hardliners, jihadists, and ISIS offshoots.4\nMaybe the key to insurgent survival is - never go it alone."
  },
  {
    "objectID": "posts/pairwise_network/network_pairwise.html#footnotes",
    "href": "posts/pairwise_network/network_pairwise.html#footnotes",
    "title": "Insurgent (Pairwise) Networks",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFotini Christia, “Alliance Formation in Civil Wars”.↩︎\nData from The Armed Conflict Location & Event Data Project (ACLED) was accessed spring of 2021. Given the hieght of the Syrian conflict occured before this time, I chose to re-use this data for this project.↩︎\nMajor Dusty Turner, U.S. Army is a monster coder and overall big brain. I’ve leaned on him for a number of problems. He consistently digs me out of a hole – all while cracking a joke.↩︎\nThe Armed Conflict Location & Event Data Project (ACLED), Actor Profile: Hayat Tahrir al-Sham (HTS) 26 July 2023.↩︎"
  },
  {
    "objectID": "posts/peacekeeping_survival/peacekeep.html",
    "href": "posts/peacekeeping_survival/peacekeep.html",
    "title": "Parametric Survival Analysis: UN Peacekeeping Missions",
    "section": "",
    "text": "Image Source: https://peacekeeping.un.org/en/department-of-peace-operations\n\n\nThis topic has been on my mind for a while. I theorize (based on nothing but my gut) that there might be a relationship between the duration of a peacekeeping mission and the type of war that just occurred.\nIt seems plausible that civil wars have dynamics that exacerbate peacekeeping missions. Civil wars represent neighbors fighting for control of terrain and power over the respective inhabitants. Grievances commonly persist beyond the resolution of open conflict. Peace is fragile and vulnerable to spoilers, grudges, and revenge-seeking—all of which represent challenges to peacekeeping missions.\nOn the other hand, generally speaking, interstate wars might have more clearly defined objectives and could be resolved more swiftly through diplomatic means or clearly defined peace agreements, leading to comparatively shorter peacekeeping mission durations.\n\n\n\n\n\n\nIn short:\n\n\n\nWars vary widely in terms of internal and external dynamics—most of which linger as peacekeeping missions try to stabilize the situation. Is there a relationship between war type and peacekeeping mission duration?\n\n\nSo, here I will conduct a parametric event history (AKA survival) analysis, a statistical technique that unravels “time-to-event” data. The “event” in this case is the completion of the peacekeeping mission for each type of war: civil war (civil), interstate war (interst), and intrastate war (icw).\nObviously, there are several steps in this process. Even more confusing is the multitude of different models. Keeping everything straight can be a bit messy: parametric vs. non-parametric models, proportional hazards vs. accelerated failure time models, monotonic vs. non-monotonic distributions, and the various combinations.\nI grabbed a happy snap of how these models were summarized on the white board. I’ve kept this happy snap filed away.\n\n\nPH: Proportional hazards\nAFT: Accelerated Failure time\n\nIn short/general, we can say that Kaplan-Meier estimation provides descriptive survival information, while the catalog of parametric models and Cox models offer more advanced statistical analysis of survival data, allowing for hypothesis testing and the examination of covariate effects. They can be used together to provide a comprehensive understanding of survival patterns and relationships.\n\n\n\n\n\n\n\n\n\nI will fit a few parametric survival models using different distributions. Last, I’ll look at the (non-parametric) Cox proportional hazards model, which offers an alternative perspective on analyzing covariate effects.\n\n\nCode\nlibrary(haven)\nlibrary(tidyverse)\nlibrary(flexsurv)\nlibrary(survival)\nlibrary(survminer)\nlibrary(ggsurvfit)\nlibrary(coxed)\n#library(texreg)\nsource('my_gg_theme.R')\n\n\n\n\n\n\n\n\nImportant\n\n\n\nI implemented all models in both R and Python (See respective tabs). The results, of course, are marginally different likely a result of rounding error. Therefore, I base all interpretations on the results from R for no good reason."
  },
  {
    "objectID": "posts/peacekeeping_survival/peacekeep.html#load-clean-and-look-at-the-data",
    "href": "posts/peacekeeping_survival/peacekeep.html#load-clean-and-look-at-the-data",
    "title": "Parametric Survival Analysis: UN Peacekeeping Missions",
    "section": "Load, Clean and Look at the Data",
    "text": "Load, Clean and Look at the Data\nIn the context of implementing a survival model using flexsurvreg() in R, the appropriate shape of the dataframe depends on how you want to model the relationship between the covariates and the survival outcome. Both dataframe structures you provided are valid, but they represent different ways of specifying the covariates in the model.\n\n\nCode\nun_df &lt;- \n  read_dta('UNdata.dta') %&gt;% \n  select(failed, duration, civil, interst, icw) %&gt;%  \n  drop_na()\n\n# references\n# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5868723/\n# https://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html#Kaplan-Meier_plots\n# https://lifelines.readthedocs.io/en/latest/lifelines.plotting.html\n\n# reshaping to experiment\nun_df_cat &lt;- \n  un_df %&gt;% \n  mutate(\n    wartype = factor(\n      if_else(civil == 1,\n              'civil',\n              if_else(interst == 1,\n                      'interst',\n                      'icw')))) %&gt;%\n  mutate(wartype = \n           fct_relevel(wartype,\n                       \"icw\",\n                       \"civil\",\n                       \"interst\")) %&gt;% \n  select(-c(civil, interst, icw))\n\n# Python requrres numeric\nun_df_num &lt;- \n  un_df %&gt;% \n  mutate(\n    wartype = \n      if_else(civil == 1,\n              1,\n              if_else(interst == 1,\n                      2,\n                      3))) %&gt;% \n  select(-c(civil, interst, icw))\n\nun_df %&gt;% \n  head() %&gt;% \n  knitr::kable()\n\n\n\n\n\nfailed\nduration\ncivil\ninterst\nicw\n\n\n\n\n1\n2\n0\n0\n1\n\n\n1\n4\n1\n0\n0\n\n\n1\n5\n0\n0\n1\n\n\n1\n5\n1\n0\n0\n\n\n1\n7\n0\n0\n1\n\n\n1\n7\n0\n1\n0"
  },
  {
    "objectID": "posts/peacekeeping_survival/peacekeep.html#question-2",
    "href": "posts/peacekeeping_survival/peacekeep.html#question-2",
    "title": "Peacekeeping Missions and Event History (AKA Survival) Analysis",
    "section": "Question 2",
    "text": "Question 2\n\n\n\n\n\n\nPrompt:\n\n\n\nEstimate a parametric survival model using the generalized gamma distribution and interpret the coefficient estimates.\n\n\n\nR solutionPython Solution\n\n\nIntercept only (NULL) model:\n\n\nCode\n## Estimate parametric models - Generalized gamma\n\ngamma_fit &lt;- flexsurvreg(\n  formula = \n    Surv(time = duration,\n         event = failed) ~ 1,\n  data = un_df,\n  dist = \"gengamma\"\n  )\n\ngamma_fit \n\n\nCall:\nflexsurvreg(formula = Surv(time = duration, event = failed) ~ \n    1, data = un_df, dist = \"gengamma\")\n\nEstimates: \n       est     L95%    U95%    se    \nmu      2.921   2.326   3.516   0.304\nsigma   1.325   1.034   1.698   0.168\nQ      -1.212  -2.003  -0.422   0.403\n\nN = 54,  Events: 39,  Censored: 15\nTotal time at risk: 3994\nLog-likelihood = -197.3282, df = 3\nAIC = 400.6565\n\n\nWhen using a wide dataframe (stratified war type with cols = civil, interst, and icw), R produces:\n\n\nCode\n## Estimate parametric models - Generalized gamma\n\ngamma_fit &lt;- flexsurvreg(\n  formula = \n    Surv(time = duration,\n         event = failed) ~ civil + interst,\n  data = un_df,\n  dist = \"gengamma\"\n  )\n\ngamma_fit \n\n\nCall:\nflexsurvreg(formula = Surv(time = duration, event = failed) ~ \n    civil + interst, data = un_df, dist = \"gengamma\")\n\nEstimates: \n         data mean  est      L95%     U95%     se       exp(est)  L95%   \nmu            NA     3.0254   2.2488   3.8019   0.3962       NA        NA\nsigma         NA     1.3252   1.0380   1.6917   0.1651       NA        NA\nQ             NA    -0.9043  -1.8681   0.0595   0.4917       NA        NA\ncivil     0.2593    -0.2528  -1.1581   0.6525   0.4619   0.7766    0.3141\ninterst   0.1852     0.9711  -0.0535   1.9957   0.5228   2.6408    0.9479\n         U95%   \nmu            NA\nsigma         NA\nQ             NA\ncivil     1.9203\ninterst   7.3575\n\nN = 54,  Events: 39,  Censored: 15\nTotal time at risk: 3994\nLog-likelihood = -195.346, df = 5\nAIC = 400.692\n\n\nI reshaped to include a wartype covariate that collapses the three types of war to war column – primarily because this is the shape required for Python. Note that R can handle it either way:\n\n\nCode\nun_df_cat %&gt;% \n  head() %&gt;% \n  knitr::kable()\n\n\n\n\n\nfailed\nduration\nwartype\n\n\n\n\n1\n2\nicw\n\n\n1\n4\ncivil\n\n\n1\n5\nicw\n\n\n1\n5\ncivil\n\n\n1\n7\nicw\n\n\n1\n7\ninterst\n\n\n\n\n\n\n\nCode\n## Estimate parametric models - Generalized gamma\n\ngamma_fit &lt;- flexsurvreg(\n  formula = \n    Surv(time = duration,\n         event = failed) ~ wartype,\n  data = un_df_cat,\n  dist = \"gengamma\"\n  )\n\ngamma_fit \n\n\nCall:\nflexsurvreg(formula = Surv(time = duration, event = failed) ~ \n    wartype, data = un_df_cat, dist = \"gengamma\")\n\nEstimates: \n                data mean  est      L95%     U95%     se       exp(est)\nmu                   NA     3.0254   2.2488   3.8019   0.3962       NA \nsigma                NA     1.3252   1.0380   1.6917   0.1651       NA \nQ                    NA    -0.9043  -1.8681   0.0595   0.4917       NA \nwartypecivil     0.2593    -0.2528  -1.1581   0.6525   0.4619   0.7766 \nwartypeinterst   0.1852     0.9711  -0.0535   1.9957   0.5228   2.6408 \n                L95%     U95%   \nmu                   NA       NA\nsigma                NA       NA\nQ                    NA       NA\nwartypecivil     0.3141   1.9203\nwartypeinterst   0.9479   7.3575\n\nN = 54,  Events: 39,  Censored: 15\nTotal time at risk: 3994\nLog-likelihood = -195.346, df = 5\nAIC = 400.692\n\n\nAccelerated Failure Time Models:\nAssumption: The accelerated failure time (AFT) model assumes that the covariates have a multiplicative effect on the survival time or the time-to-event variable. In other words, the model assumes that the covariates accelerate or decelerate the time scale in a linear way.\nCivil War\nFor an AFT model, the coefficient (call it \\(\\beta_1\\)) represents the log of the time ratio associated with the covariate. In this case, the covariate civil1 is binary, and it compares the effect of being in the group civil1 (compared to the reference group civil0) on the survival time. Since the coefficient is -0.26, we would take the exponential of the coefficient (i.e., exp(-0.26)) to get the time ratio. (Time Ratio: exp(-0.26) ≈ 0.78)\nSo, wars in the group civil1 have a survival time that is approximately 0.78 times shorter (or 22% shorter) compared to wars in the reference group civil0, all other factors being equal.\nSince the coefficient is negative, it suggests that being in the civil1 group is associated with shorter survival times (an accelerating effect on the event time) compared to the reference group civil0.\nInterstate War\nFor interstate war, the time Ratio: exp(0.9711) ≈ 2.6408 indicates that wars in the group interst1 have a survival time that is approximately 2.64 times longer (or 164% longer) compared to wars in the reference group interst0, all other factors being equal.\nSince the coefficient is positive, it suggests that being in the interst1 group is associated with longer survival times (a decelerating effect on the event time) compared to the reference group interst0.\n\n\n\nA Null model\n\n\nCode\n# https://lifelines.readthedocs.io/en/latest/Survival%20Regression.htmlAC\n\ndf = r.un_df_num\ndf['Intercept'] = 1.\n\n# create parameters &lt;-&gt; covariates dict\n# The values in the dict become can be formulas, or column names in lists:\nregressors = {\n    'mu_': df.columns.difference(['failed', 'duration']),\n    'sigma_': [\"wartype\", \"Intercept\"],\n    'lambda_': 'wartype + 1',\n}\n\n# this will regress df against all 3 parameters\n# gg_model = GeneralizedGammaRegressionFitter(penalizer=1.).\\\n#     fit(df, 'duration', 'failed')\n\ngg_model = GeneralizedGammaRegressionFitter(penalizer=0.0001).\\\n    fit(df, 'duration', 'failed', regressors=regressors)\n    \ngg_model.print_summary()\n\n\n&lt;lifelines.GeneralizedGammaRegressionFitter: fitted with 54 total observations, 15 right-censored observations&gt;\n             duration col = 'duration'\n                event col = 'failed'\n                penalizer = 0.0001\n   number of observations = 54\nnumber of events observed = 39\n           log-likelihood = -196.38\n         time fit was run = 2023-08-24 01:40:16 UTC\n\n---\n                    coef  exp(coef)   se(coef)   coef lower 95%   coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%\nparam   covariate                                                                                                         \nmu_     Intercept   2.69      14.73       1.31             0.11             5.27                 1.12               193.60\n        wartype     0.10       1.11       0.57            -1.02             1.23                 0.36                 3.41\nsigma_  wartype     0.21       1.23       0.77            -1.29             1.71                 0.27                 5.53\n        Intercept  -0.21       0.81       0.27            -0.74             0.32                 0.48                 1.38\nlambda_ Intercept  -0.71       0.49       0.13            -0.97            -0.46                 0.38                 0.63\n        wartype    -0.22       0.80       0.42            -1.04             0.60                 0.35                 1.82\n\n                    cmp to     z      p   -log2(p)\nparam   covariate                                 \nmu_     Intercept     0.00  2.05   0.04       4.62\n        wartype       0.00  0.18   0.86       0.22\nsigma_  wartype       0.00  0.27   0.78       0.35\n        Intercept     0.00 -0.78   0.44       1.20\nlambda_ Intercept     0.00 -5.47 &lt;0.005      24.38\n        wartype       0.00 -0.52   0.60       0.74\n---\nAIC = 404.76\nlog-likelihood ratio test = 1.90 on 3 df\n-log2(p) of ll-ratio test = 0.75\n\n\nCumulative Hazard Rates\n\n\nCode\ngg_model.plot()\nplt.show();"
  },
  {
    "objectID": "posts/peacekeeping_survival/peacekeep.html#a-null-model",
    "href": "posts/peacekeeping_survival/peacekeep.html#a-null-model",
    "title": "Parametric Survival Analysis: UN Peacekeeping Missions",
    "section": "A Null model",
    "text": "A Null model\n\n\nCode\n# https://lifelines.readthedocs.io/en/latest/Survival%20Regression.htmlAC\n\ndf = r.un_df_num\ndf['Intercept'] = 1.\n\n# create parameters &lt;-&gt; covariates dict\n# The values in the dict become can be formulas, or column names in lists:\nregressors = {\n    'mu_': df.columns.difference(['failed', 'duration']),\n    'sigma_': [\"wartype\", \"Intercept\"],\n    'lambda_': 'wartype + 1',\n}\n\n# this will regress df against all 3 parameters\n# gg_model = GeneralizedGammaRegressionFitter(penalizer=1.).\\\n#     fit(df, 'duration', 'failed')\n\ngg_model = GeneralizedGammaRegressionFitter(penalizer=0.0001).\\\n    fit(df, 'duration', 'failed', regressors=regressors)\n    \ngg_model.print_summary()\n\n\n&lt;lifelines.GeneralizedGammaRegressionFitter: fitted with 54 total observations, 15 right-censored observations&gt;\n             duration col = 'duration'\n                event col = 'failed'\n                penalizer = 0.0001\n   number of observations = 54\nnumber of events observed = 39\n           log-likelihood = -196.38\n         time fit was run = 2023-08-27 18:54:06 UTC\n\n---\n                    coef  exp(coef)   se(coef)   coef lower 95%   coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%\nparam   covariate                                                                                                         \nmu_     Intercept   2.69      14.73       1.31             0.11             5.27                 1.12               193.60\n        wartype     0.10       1.11       0.57            -1.02             1.23                 0.36                 3.41\nsigma_  wartype     0.21       1.23       0.77            -1.29             1.71                 0.27                 5.53\n        Intercept  -0.21       0.81       0.27            -0.74             0.32                 0.48                 1.38\nlambda_ Intercept  -0.71       0.49       0.13            -0.97            -0.46                 0.38                 0.63\n        wartype    -0.22       0.80       0.42            -1.04             0.60                 0.35                 1.82\n\n                    cmp to     z      p   -log2(p)\nparam   covariate                                 \nmu_     Intercept     0.00  2.05   0.04       4.62\n        wartype       0.00  0.18   0.86       0.22\nsigma_  wartype       0.00  0.27   0.78       0.35\n        Intercept     0.00 -0.78   0.44       1.20\nlambda_ Intercept     0.00 -5.47 &lt;0.005      24.38\n        wartype       0.00 -0.52   0.60       0.74\n---\nAIC = 404.76\nlog-likelihood ratio test = 1.90 on 3 df\n-log2(p) of ll-ratio test = 0.75\n\n\nCumulative Hazard Rates\n\n\nCode\ngg_model.plot()\nplt.show();"
  },
  {
    "objectID": "posts/peacekeeping_survival/peacekeep.html#question-3",
    "href": "posts/peacekeeping_survival/peacekeep.html#question-3",
    "title": "Peacekeeping Missions and Event History (AKA Survival) Analysis",
    "section": "Question 3",
    "text": "Question 3\n\n\n\n\n\n\nPrompt:\n\n\n\nHere I choose one monotonic distribution and one non-monotonic distribution and estimate additional parametric survival models and interpret the results.\n\n\n\nR SolutionPython Solution\n\n\nMonotonic Distribution\n\n\nCode\n## Estimate parametric models - Generalized gamma\n\nmonot_fit &lt;- flexsurvreg(\n  formula = \n    Surv(time = duration,\n         event = failed) ~ wartype,\n  data = un_df_cat,\n  dist = \"weibull\"\n  )\n\nmonot_fit \n\n\nCall:\nflexsurvreg(formula = Surv(time = duration, event = failed) ~ \n    wartype, data = un_df_cat, dist = \"weibull\")\n\nEstimates: \n                data mean  est       L95%      U95%      se        exp(est)\nshape                 NA     0.8069    0.6331    1.0285    0.0999        NA\nscale                 NA    72.8156   43.2961  122.4616   19.3139        NA\nwartypecivil      0.2593    -1.1004   -1.9741   -0.2267    0.4458    0.3327\nwartypeinterst    0.1852     1.7368    0.5284    2.9452    0.6165    5.6793\n                L95%      U95%    \nshape                 NA        NA\nscale                 NA        NA\nwartypecivil      0.1389    0.7972\nwartypeinterst    1.6963   19.0152\n\nN = 54,  Events: 39,  Censored: 15\nTotal time at risk: 3994\nLog-likelihood = -201.1528, df = 4\nAIC = 410.3055\n\n\nNon-Monotonic Distribution\n\n\nCode\n## Estimate parametric models - Generalized gamma\n\nnon_mono_fit &lt;- flexsurvreg(\n  formula = \n    Surv(time = duration,\n         event = failed) ~ wartype,\n  data = un_df_cat,\n  dist = \"lognormal\"\n  )\n\nnon_mono_fit \n\n\nCall:\nflexsurvreg(formula = Surv(time = duration, event = failed) ~ \n    wartype, data = un_df_cat, dist = \"lognormal\")\n\nEstimates: \n                data mean  est     L95%    U95%    se      exp(est)  L95%  \nmeanlog             NA      3.592   3.081   4.103   0.261      NA        NA\nsdlog               NA      1.365   1.080   1.724   0.163      NA        NA\nwartypecivil     0.259     -0.590  -1.483   0.304   0.456   0.555     0.227\nwartypeinterst   0.185      1.385   0.319   2.451   0.544   3.995     1.376\n                U95%  \nmeanlog             NA\nsdlog               NA\nwartypecivil     1.355\nwartypeinterst  11.597\n\nN = 54,  Events: 39,  Censored: 15\nTotal time at risk: 3994\nLog-likelihood = -196.7765, df = 4\nAIC = 401.5531\n\n\n\n\nWeibull Distribution\n\n\nCode\nweibull_model = WeibullFitter().\\\n    fit(r.un_df_num['duration'], event_observed = r.un_df_num['failed'])\n\nprint(weibull_model.summary)\n\n\n              coef   se(coef)  coef lower 95%  ...         z         p   -log2(p)\nlambda_  87.564550  22.050354       44.346651  ...  3.925767  0.000086  13.497710\nrho_      0.636418   0.076044        0.487374  ... -4.781193  0.000002  19.130345\n\n[2 rows x 8 columns]\n\n\n\n\nCode\n# weibull_model.plot()\nweibull_model.plot()\nplt.show();\n\n\n\n\n\n\n\nCode\n# create an exponential model\nlogn_model = LogNormalFitter().\\\n    fit(r.un_df['duration'], event_observed = r.un_df['failed'])\n\nprint(logn_model.summary)\n\n\n            coef  se(coef)  coef lower 95%  ...          z             p    -log2(p)\nmu_     3.710521  0.220683        3.277989  ...  16.813784  1.934223e-63  208.329716\nsigma_  1.527447  0.182320        1.170107  ...   2.892978  3.816083e-03    8.033692\n\n[2 rows x 8 columns]\n\n\n\n\nCode\nlogn_model.plot()\nplt.show();"
  },
  {
    "objectID": "posts/peacekeeping_survival/peacekeep.html#question-4",
    "href": "posts/peacekeeping_survival/peacekeep.html#question-4",
    "title": "Peacekeeping Missions and Event History (AKA Survival) Analysis",
    "section": "Question 4",
    "text": "Question 4\n\n\n\n\n\n\nPrompt:\n\n\n\nEstimate a Cox model and interpret the coefficient estimates.\n\n\n\nR SolutionPython Solution\n\n\n\n\n\nCode\n#library(gtsummary)\nsummary(cox1 &lt;- \n          coxph(Surv(time = duration,\n                     event = failed) ~ \n                  civil + interst, \n                data = un_df,\n                ties = \"efron\"))\n\n\nCall:\ncoxph(formula = Surv(time = duration, event = failed) ~ civil + \n    interst, data = un_df, ties = \"efron\")\n\n  n= 54, number of events= 39 \n\n           coef exp(coef) se(coef)      z Pr(&gt;|z|)  \ncivil    0.7561    2.1300   0.3798  1.991   0.0465 *\ninterst -0.8723    0.4180   0.5041 -1.730   0.0835 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n        exp(coef) exp(-coef) lower .95 upper .95\ncivil       2.130     0.4695    1.0118     4.484\ninterst     0.418     2.3923    0.1556     1.123\n\nConcordance= 0.619  (se = 0.042 )\nLikelihood ratio test= 9.32  on 2 df,   p=0.009\nWald test            = 8.65  on 2 df,   p=0.01\nScore (logrank) test = 9.5  on 2 df,   p=0.009\n\n\nCode\n# cox1 %&gt;% \n#   tbl_regression(exp = TRUE) \n\n# summary(cox2 &lt;- \n#           coxph(Surv(time = duration,\n#                      event = failed) ~ \n#                   wartype, \n#                 data = un_df_cat,\n#                 ties = \"efron\"))\n\n# cox3 %&gt;% \n#   tbl_regression(exp = TRUE)\n\n\nCox proportional hazards regression model is used to analyze the association between covariates and the hazard function (the risk of an event occurring at a specific time) in survival data. The Cox proportional hazards model assumes that the hazard for any individual is proportional to the hazard for any other individual at all time points. This means that the hazard ratio between two groups remains constant over time.\nAlternatively, we can think of the hazard rates obtained from the Cox proportional hazards model represent the estimated instantaneous risk of an event occurring at a particular time. More specifically, the hazard rate at a specific time represents the conditional probability that an event will occur at that time, given that the individual has survived up to that time and has the specific covariate values.\nIn the context of categorical covariates, the hazard rates obtained for different levels of the categorical variable indicate how the risk of the event changes over time compared to the reference group. A hazard rate greater than 1 indicates a higher risk (higher probability of an event occurring) relative to the reference group.\ncivil1:\n\nCoefficient (beta): 0.76\nHazard Ratio (exp(coef)): 2.13\n\nInterpretation: Individuals in the civil1 group have a hazard (risk) of experiencing the event (ending of peacekeeping mission) approximately 2.13 times higher than individuals in the reference group civil0, all other factors being equal. (The coefficient is statistically significant at the 0.05 level)\ninterst1:\n\nCoefficient (beta): -0.87\nHazard Ratio (exp(coef)): 0.42\n\nInterpretation: Individuals in the interst1 group have a hazard (risk) of experiencing the event approximately 0.42 times lower (or 58.2% lower) than individuals in the reference group interst0, all other factors being equal. (The coefficient is statistically significant at the 0.10 level)\n\n\n\n\nCode\ncph_model = CoxPHFitter()\n\ncph_model.fit(r.un_df, \n    duration_col = 'duration', \n    event_col = 'failed', \n    formula = 'civil + interst')\n\n\n&lt;lifelines.CoxPHFitter: fitted with 54 total observations, 15 right-censored observations&gt;\n\n\nCode\nprint(cph_model.summary)\n\n\n               coef  exp(coef)  se(coef)  ...         z         p  -log2(p)\ncovariate                                 ...                              \ncivil      0.756088   2.129929  0.379778  ...  1.990868  0.046495  4.426767\ninterst   -0.872107   0.418070  0.504038  ... -1.730241  0.083587  3.580575\n\n[2 rows x 11 columns]\n\n\n\n\nCode\ncph_model.plot()\nplt.show()\n\n\n\n\n\n\nQuestion 5\n\n\n\n\n\n\nPrompt:\n\n\n\nOf the four estimated models, identify the “best”-fitting model and justify your selection. Produce plots of the survival function and hazard rate based on your chosen model.\n\n\nLet’s pick the model with the lowest AIC:\n\n\nCode\ndata = {\n  \"log Normal\": [round(logn_model.AIC_,2), round(logn_model.BIC_,2)],\n  \"Weibull\": [round(weibull_model.AIC_,2), round(weibull_model.BIC_,2)],\n  \"Gen Gamma\": [round(gg_model.AIC_,2), round(gg_model.BIC_,2)]\n}\n\npy_mod_metric = pd.DataFrame(data, index = [['AIC', 'BIC']]).\\\n    rename_axis(\"Metric\").\\\n    reset_index()\n\n\n\n\nCode\nlibrary(reticulate)\n\npy$py_mod_metric %&gt;% \n  knitr::kable()\n\n\n\n\n\nMetric\nlog Normal\nWeibull\nGen Gamma\n\n\n\n\nAIC\n407.57\n423.97\n404.76\n\n\nBIC\n411.55\n427.95\n404.72"
  },
  {
    "objectID": "posts/peacekeeping_survival/peacekeep.html#question-5",
    "href": "posts/peacekeeping_survival/peacekeep.html#question-5",
    "title": "Parametric Survival Analysis: UN Peacekeeping Missions",
    "section": "Question 5",
    "text": "Question 5\n\n\n\n\n\n\nPrompt:\n\n\n\nOf the four estimated models, identify the “best”-fitting model and justify your selection. Produce plots of the survival function and hazard rate based on your chosen model.\n\n\nLet’s pick the model with the lowest AIC:\n\n\nCode\ndata = {\n  \"log Normal\": [round(logn_model.AIC_,2), round(logn_model.BIC_,2)],\n  \"Weibull\": [round(weibull_model.AIC_,2), round(weibull_model.BIC_,2)],\n  \"Gen Gamma\": [round(gg_model.AIC_,2), round(gg_model.BIC_,2)]\n}\n\npy_mod_metric = pd.DataFrame(data, index = [['AIC', 'BIC']]).\\\n    rename_axis(\"Metric\").\\\n    reset_index()\n\n\n\n\nCode\nlibrary(reticulate)\n\npy$py_mod_metric %&gt;% \n  knitr::kable()\n\n\n\n\n\nMetric\nlog Normal\nWeibull\nGen Gamma\n\n\n\n\nAIC\n407.57\n423.97\n404.76\n\n\nBIC\n411.55\n427.95\n404.72"
  },
  {
    "objectID": "posts/peacekeeping_survival/peacekeep.html#question-6",
    "href": "posts/peacekeeping_survival/peacekeep.html#question-6",
    "title": "Peacekeeping Missions and Event History (AKA Survival) Analysis",
    "section": "Question 6",
    "text": "Question 6\n\n\n\n\n\n\nPrompt:\n\n\n\nExplain the consequences of estimating a parametric survival model with an incorrect distribution.\n\n\nIn short, the suitability of any distribution for your data depends on how well it fits the underlying data-generating process.\nBefore implementing a model, we must give thought to the data generating process or the underlying mechanism or model that generates the observed data. We represent these processes through distributions–and the respective distributional parameters. Using an incorrect parametric distribution (Weibull for instance) when the true distribution is Gamma can result in biased parameter estimates, poor model fit, and inaccurate survival predictions (among other things) because the respective distribution parameters (shape and scale) are significantly different."
  },
  {
    "objectID": "posts/peacekeeping_survival/peacekeep.html#appendix",
    "href": "posts/peacekeeping_survival/peacekeep.html#appendix",
    "title": "Peacekeeping Missions and Event History (AKA Survival) Analysis",
    "section": "Appendix",
    "text": "Appendix\nI grabbed a picture of how my professor organized these models. I’ve kept this happy snap filed away."
  },
  {
    "objectID": "posts/peacekeeping_survival/peacekeep.html#war-type-and-peacekeeping-mission-duration",
    "href": "posts/peacekeeping_survival/peacekeep.html#war-type-and-peacekeeping-mission-duration",
    "title": "Parametric Survival Analysis: UN Peacekeeping Missions",
    "section": "",
    "text": "Image Source: https://peacekeeping.un.org/en/department-of-peace-operations\n\n\nThis topic has been on my mind for a while. I theorize (based on nothing but my gut) that there might be a relationship between the duration of a peacekeeping mission and the type of war that just occurred.\nIt seems plausible that civil wars have dynamics that exacerbate peacekeeping missions. Civil wars represent neighbors fighting for control of terrain and power over the respective inhabitants. Grievances commonly persist beyond the resolution of open conflict. Peace is fragile and vulnerable to spoilers, grudges, and revenge-seeking—all of which represent challenges to peacekeeping missions.\nOn the other hand, generally speaking, interstate wars might have more clearly defined objectives and could be resolved more swiftly through diplomatic means or clearly defined peace agreements, leading to comparatively shorter peacekeeping mission durations.\n\n\n\n\n\n\nIn short:\n\n\n\nWars vary widely in terms of internal and external dynamics—most of which linger as peacekeeping missions try to stabilize the situation. Is there a relationship between war type and peacekeeping mission duration?\n\n\nSo, here I will conduct a parametric event history (AKA survival) analysis, a statistical technique that unravels “time-to-event” data. The “event” in this case is the completion of the peacekeeping mission for each type of war: civil war (civil), interstate war (interst), and intrastate war (icw).\nObviously, there are several steps in this process. Even more confusing is the multitude of different models. Keeping everything straight can be a bit messy: parametric vs. non-parametric models, proportional hazards vs. accelerated failure time models, monotonic vs. non-monotonic distributions, and the various combinations.\nI grabbed a happy snap of how these models were summarized on the white board. I’ve kept this happy snap filed away.\n\n\nPH: Proportional hazards\nAFT: Accelerated Failure time\n\nIn short/general, we can say that Kaplan-Meier estimation provides descriptive survival information, while the catalog of parametric models and Cox models offer more advanced statistical analysis of survival data, allowing for hypothesis testing and the examination of covariate effects. They can be used together to provide a comprehensive understanding of survival patterns and relationships.\n\n\n\n\n\n\n\n\n\nI will fit a few parametric survival models using different distributions. Last, I’ll look at the (non-parametric) Cox proportional hazards model, which offers an alternative perspective on analyzing covariate effects.\n\n\nCode\nlibrary(haven)\nlibrary(tidyverse)\nlibrary(flexsurv)\nlibrary(survival)\nlibrary(survminer)\nlibrary(ggsurvfit)\nlibrary(coxed)\n#library(texreg)\nsource('my_gg_theme.R')\n\n\n\n\n\n\n\n\nImportant\n\n\n\nI implemented all models in both R and Python (See respective tabs). The results, of course, are marginally different likely a result of rounding error. Therefore, I base all interpretations on the results from R for no good reason."
  },
  {
    "objectID": "posts/peacekeeping_survival/peacekeep.html#kaplan-meier-plot",
    "href": "posts/peacekeeping_survival/peacekeep.html#kaplan-meier-plot",
    "title": "Parametric Survival Analysis: UN Peacekeeping Missions",
    "section": "Kaplan-Meier Plot",
    "text": "Kaplan-Meier Plot\nInitial (descriptive) look at the data: The survival probability reflects the likelihood of an individual surviving or not experiencing the event up to that time point. It ranges from 0 to 1, with 0 indicating no survival (event occurred) and 1 indicating complete survival (no event occurred). Each curve below represents a different group within the study, and we see distinct differences in survival probabilities between the groups.\n\nR solutionPython Solution\n\n\n\n\nCode\nsurvfit2(Surv(duration, failed) ~ 1, data = un_df) %&gt;% \n  ggsurvfit() +\n  labs(\n    x = \"Days\",\n    y = \"Survival probability\",\n    title = \"Peacekeeping missions: Overall survival probability\"\n  ) + \n  add_confidence_interval() +\n  add_risktable() +\n  my_gg_theme\n\n\n\n\n\nWe can use the summary() to find the probability of surviving to 1 year, which is approximately 20%. (Note: the time variable in the data is actually in days, so we need to use times = 365.25)\n\n\nCode\nsummary(survfit(\n  Surv(duration, failed) ~ 1, \n  data = un_df), \n  times = 365.25)\n\n\nCall: survfit(formula = Surv(duration, failed) ~ 1, data = un_df)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n  365      3      39    0.196   0.063        0.105        0.369\n\n\n\n\nCode\nsurvfit2(Surv(duration, failed) ~ \n           civil + interst + icw, \n         data = un_df) %&gt;% \n  ggsurvfit() +\n  labs(\n    x = \"Days\",\n    y = \"Survival probability\",\n    title = \"Peacekeeping missions: Survival probability by Type\"\n  ) + \n  add_risktable() +\n  my_gg_theme\n\n\n\n\n\n\n\nAccording to the Python documentation, these plots show the survival function of the model plus it’s area-under-the-curve (AUC) up until the point t. The AUC is known as the restricted mean survival time (RMST).\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom lifelines import GeneralizedGammaFitter, ExponentialFitter, WeibullFitter, CoxPHFitter, LogNormalFitter\nfrom lifelines import GeneralizedGammaRegressionFitter\n\nfrom lifelines.utils import restricted_mean_survival_time\nfrom lifelines.datasets import load_waltons\nfrom lifelines.plotting import rmst_plot, plot_lifetimes\nfrom lifelines import KaplanMeierFitter\nfrom lifelines.plotting import rmst_plot\n\n\n\n\nCode\n# https://lifelines.readthedocs.io/en/latest/lifelines.plotting.html\n \ndf = r.un_df_cat\n\ntime_limit = 10\n\n# Create Kaplan-Meier fitted objects for each group\nkmf_civil = KaplanMeierFitter().\\\n    fit(df['duration'], df['failed']) # label='wartype'\n\nrmst_plot(kmf_civil, t=time_limit, show_censors=False)\n\nplt.xlabel('Time')\nplt.ylabel('RMST')\nplt.title('Overall Restricted Mean Survival Time (RMST) Plot - wide df')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nCode\n# https://lifelines.readthedocs.io/en/latest/lifelines.plotting.html\n\ndf = r.un_df\n# Separate the data into groups based on 'civil' and 'interst'\nix_civil = df['civil'] == \"1\"\nix_interst = df['interst'] == \"1\"\nix_icw = df['icw'] == \"1\"\n\n# Create Kaplan-Meier fitted objects for each group\nkmf_civil = KaplanMeierFitter().\\\n    fit(df['duration'][ix_civil], df['failed'][ix_civil], label='Civil War')\n    \nkmf_interst = KaplanMeierFitter().\\\n    fit(df['duration'][ix_interst], df['failed'][ix_interst], label='Interstate War')\n    \nkmf_icw = KaplanMeierFitter().\\\n    fit(df['duration'][ix_icw], df['failed'][ix_icw], label='icw')\n\n# Plot RMST for each group\nax = plt.subplot(111)\nrmst_plot(kmf_civil, t=10, ax=ax, show_censors=False)\nrmst_plot(kmf_interst, t=10, ax=ax, show_censors=False)\nrmst_plot(kmf_icw, t=10, ax=ax, show_censors=False)\n\nplt.xlabel('Time')\nplt.ylabel('RMST')\nplt.title('Restricted Mean Survival Time (RMST) Plot')\nplt.legend()\nplt.show()\n\n\n\n\nCode\ndf = r.un_df_cat\n# Separate the data into groups based on 'civil' and 'interst'\nix_civil = df['wartype'] == \"civil\"\nix_interst = df['wartype'] == \"interst\"\nix_icw = df['wartype'] == \"icw\"\ntime_limit = 10\n\n# Create Kaplan-Meier fitted objects for each group\nkmf_civil = KaplanMeierFitter().\\\n    fit(df['duration'][ix_civil], df['failed'][ix_civil], label='Civil War')\n    \nkmf_interst = KaplanMeierFitter().\\\n    fit(df['duration'][ix_interst], df['failed'][ix_interst], label='Interstate War')\n    \nkmf_icw = KaplanMeierFitter().\\\n    fit(df['duration'][ix_icw], df['failed'][ix_icw], label='icw')\n\n# Plot RMST for each group\nax = plt.subplot(111)\nrmst_plot(kmf_civil, t=time_limit, ax=ax, show_censors=False)\nrmst_plot(kmf_interst, t=time_limit, ax=ax, show_censors=False)\nrmst_plot(kmf_icw, t=time_limit, ax=ax, show_censors=False)\n\nplt.xlabel('Time')\nplt.ylabel('RMST')\nplt.title('Restricted Mean Survival Time (RMST) Plot')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/peacekeeping_survival/peacekeep.html#fit-the-model",
    "href": "posts/peacekeeping_survival/peacekeep.html#fit-the-model",
    "title": "Parametric Survival Analysis: UN Peacekeeping Missions",
    "section": "Fit the model",
    "text": "Fit the model\n\n\n\n\n\n\nPrompt:\n\n\n\nEstimate a parametric survival model using the generalized gamma distribution and interpret the coefficient estimates.\n\n\n\nR solutionPython Solution\n\n\nIntercept only (NULL) model:\n\n\nCode\n## Estimate parametric models - Generalized gamma\n\ngamma_fit &lt;- flexsurvreg(\n  formula = \n    Surv(time = duration,\n         event = failed) ~ 1,\n  data = un_df,\n  dist = \"gengamma\"\n  )\n\ngamma_fit \n\n\nCall:\nflexsurvreg(formula = Surv(time = duration, event = failed) ~ \n    1, data = un_df, dist = \"gengamma\")\n\nEstimates: \n       est     L95%    U95%    se    \nmu      2.921   2.326   3.516   0.304\nsigma   1.325   1.034   1.698   0.168\nQ      -1.212  -2.003  -0.422   0.403\n\nN = 54,  Events: 39,  Censored: 15\nTotal time at risk: 3994\nLog-likelihood = -197.3282, df = 3\nAIC = 400.6565\n\n\nWhen using a wide dataframe (stratified war type with cols = civil, interst, and icw), R produces:\n\n\nCode\n## Estimate parametric models - Generalized gamma\n\ngamma_fit &lt;- flexsurvreg(\n  formula = \n    Surv(time = duration,\n         event = failed) ~ civil + interst,\n  data = un_df,\n  dist = \"gengamma\"\n  )\n\ngamma_fit \n\n\nCall:\nflexsurvreg(formula = Surv(time = duration, event = failed) ~ \n    civil + interst, data = un_df, dist = \"gengamma\")\n\nEstimates: \n         data mean  est      L95%     U95%     se       exp(est)  L95%   \nmu            NA     3.0254   2.2488   3.8019   0.3962       NA        NA\nsigma         NA     1.3252   1.0380   1.6917   0.1651       NA        NA\nQ             NA    -0.9043  -1.8681   0.0595   0.4917       NA        NA\ncivil     0.2593    -0.2528  -1.1581   0.6525   0.4619   0.7766    0.3141\ninterst   0.1852     0.9711  -0.0535   1.9957   0.5228   2.6408    0.9479\n         U95%   \nmu            NA\nsigma         NA\nQ             NA\ncivil     1.9203\ninterst   7.3575\n\nN = 54,  Events: 39,  Censored: 15\nTotal time at risk: 3994\nLog-likelihood = -195.346, df = 5\nAIC = 400.692\n\n\nI reshaped to include a wartype covariate that collapses the three types of war to war column – primarily because this is the shape required for Python. Note that R can handle it either way:\n\n\nCode\nun_df_cat %&gt;% \n  head() %&gt;% \n  knitr::kable()\n\n\n\n\n\nfailed\nduration\nwartype\n\n\n\n\n1\n2\nicw\n\n\n1\n4\ncivil\n\n\n1\n5\nicw\n\n\n1\n5\ncivil\n\n\n1\n7\nicw\n\n\n1\n7\ninterst\n\n\n\n\n\n\n\nCode\n## Estimate parametric models - Generalized gamma\n\ngamma_fit &lt;- flexsurvreg(\n  formula = \n    Surv(time = duration,\n         event = failed) ~ wartype,\n  data = un_df_cat,\n  dist = \"gengamma\"\n  )\n\ngamma_fit \n\n\nCall:\nflexsurvreg(formula = Surv(time = duration, event = failed) ~ \n    wartype, data = un_df_cat, dist = \"gengamma\")\n\nEstimates: \n                data mean  est      L95%     U95%     se       exp(est)\nmu                   NA     3.0254   2.2488   3.8019   0.3962       NA \nsigma                NA     1.3252   1.0380   1.6917   0.1651       NA \nQ                    NA    -0.9043  -1.8681   0.0595   0.4917       NA \nwartypecivil     0.2593    -0.2528  -1.1581   0.6525   0.4619   0.7766 \nwartypeinterst   0.1852     0.9711  -0.0535   1.9957   0.5228   2.6408 \n                L95%     U95%   \nmu                   NA       NA\nsigma                NA       NA\nQ                    NA       NA\nwartypecivil     0.3141   1.9203\nwartypeinterst   0.9479   7.3575\n\nN = 54,  Events: 39,  Censored: 15\nTotal time at risk: 3994\nLog-likelihood = -195.346, df = 5\nAIC = 400.692\n\n\nAccelerated Failure Time Models:\nAssumption: The accelerated failure time (AFT) model assumes that the covariates have a multiplicative effect on the survival time or the time-to-event variable. In other words, the model assumes that the covariates accelerate or decelerate the time scale in a linear way.\nCivil War\nFor an AFT model, the coefficient (call it \\(\\beta_1\\)) represents the log of the time ratio associated with the covariate. In this case, the covariate civil1 is binary, and it compares the effect of being in the group civil1 (compared to the reference group civil0) on the survival time. Since the coefficient is -0.26, we would take the exponential of the coefficient (i.e., exp(-0.26)) to get the time ratio. (Time Ratio: exp(-0.26) ≈ 0.78)\nSo, wars in the group civil1 have a survival time that is approximately 0.78 times shorter (or 22% shorter) compared to wars in the reference group civil0, all other factors being equal.\nSince the coefficient is negative, it suggests that being in the civil1 group is associated with shorter survival times (an accelerating effect on the event time) compared to the reference group civil0.\nInterstate War\nFor interstate war, the time Ratio: exp(0.9711) ≈ 2.6408 indicates that wars in the group interst1 have a survival time that is approximately 2.64 times longer (or 164% longer) compared to wars in the reference group interst0, all other factors being equal.\nSince the coefficient is positive, it suggests that being in the interst1 group is associated with longer survival times (a decelerating effect on the event time) compared to the reference group interst0.\n\n\n\nA Null model\n\n\nCode\n# https://lifelines.readthedocs.io/en/latest/Survival%20Regression.htmlAC\n\ndf = r.un_df_num\ndf['Intercept'] = 1.\n\n# create parameters &lt;-&gt; covariates dict\n# The values in the dict become can be formulas, or column names in lists:\nregressors = {\n    'mu_': df.columns.difference(['failed', 'duration']),\n    'sigma_': [\"wartype\", \"Intercept\"],\n    'lambda_': 'wartype + 1',\n}\n\n# this will regress df against all 3 parameters\n# gg_model = GeneralizedGammaRegressionFitter(penalizer=1.).\\\n#     fit(df, 'duration', 'failed')\n\ngg_model = GeneralizedGammaRegressionFitter(penalizer=0.0001).\\\n    fit(df, 'duration', 'failed', regressors=regressors)\n    \ngg_model.print_summary()\n\n\n&lt;lifelines.GeneralizedGammaRegressionFitter: fitted with 54 total observations, 15 right-censored observations&gt;\n             duration col = 'duration'\n                event col = 'failed'\n                penalizer = 0.0001\n   number of observations = 54\nnumber of events observed = 39\n           log-likelihood = -196.38\n         time fit was run = 2023-08-27 18:54:06 UTC\n\n---\n                    coef  exp(coef)   se(coef)   coef lower 95%   coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%\nparam   covariate                                                                                                         \nmu_     Intercept   2.69      14.73       1.31             0.11             5.27                 1.12               193.60\n        wartype     0.10       1.11       0.57            -1.02             1.23                 0.36                 3.41\nsigma_  wartype     0.21       1.23       0.77            -1.29             1.71                 0.27                 5.53\n        Intercept  -0.21       0.81       0.27            -0.74             0.32                 0.48                 1.38\nlambda_ Intercept  -0.71       0.49       0.13            -0.97            -0.46                 0.38                 0.63\n        wartype    -0.22       0.80       0.42            -1.04             0.60                 0.35                 1.82\n\n                    cmp to     z      p   -log2(p)\nparam   covariate                                 \nmu_     Intercept     0.00  2.05   0.04       4.62\n        wartype       0.00  0.18   0.86       0.22\nsigma_  wartype       0.00  0.27   0.78       0.35\n        Intercept     0.00 -0.78   0.44       1.20\nlambda_ Intercept     0.00 -5.47 &lt;0.005      24.38\n        wartype       0.00 -0.52   0.60       0.74\n---\nAIC = 404.76\nlog-likelihood ratio test = 1.90 on 3 df\n-log2(p) of ll-ratio test = 0.75\n\n\nCumulative Hazard Rates\n\n\nCode\ngg_model.plot()\nplt.show();"
  },
  {
    "objectID": "posts/peacekeeping_survival/peacekeep.html#estimate-a-cox-model",
    "href": "posts/peacekeeping_survival/peacekeep.html#estimate-a-cox-model",
    "title": "Parametric Survival Analysis: UN Peacekeeping Missions",
    "section": "Estimate a Cox model",
    "text": "Estimate a Cox model\n\n\n\n\n\n\nEstimate a Cox model\n\n\n\nEstimate a Cox model and interpret the coefficient estimates.\n\n\n\nR SolutionPython Solution\n\n\n\n\n\nCode\n#library(gtsummary)\nsummary(cox1 &lt;- \n          coxph(Surv(time = duration,\n                     event = failed) ~ \n                  civil + interst, \n                data = un_df,\n                ties = \"efron\"))\n\n\nCall:\ncoxph(formula = Surv(time = duration, event = failed) ~ civil + \n    interst, data = un_df, ties = \"efron\")\n\n  n= 54, number of events= 39 \n\n           coef exp(coef) se(coef)      z Pr(&gt;|z|)  \ncivil    0.7561    2.1300   0.3798  1.991   0.0465 *\ninterst -0.8723    0.4180   0.5041 -1.730   0.0835 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n        exp(coef) exp(-coef) lower .95 upper .95\ncivil       2.130     0.4695    1.0118     4.484\ninterst     0.418     2.3923    0.1556     1.123\n\nConcordance= 0.619  (se = 0.042 )\nLikelihood ratio test= 9.32  on 2 df,   p=0.009\nWald test            = 8.65  on 2 df,   p=0.01\nScore (logrank) test = 9.5  on 2 df,   p=0.009\n\n\nCode\n# cox1 %&gt;% \n#   tbl_regression(exp = TRUE) \n\n# summary(cox2 &lt;- \n#           coxph(Surv(time = duration,\n#                      event = failed) ~ \n#                   wartype, \n#                 data = un_df_cat,\n#                 ties = \"efron\"))\n\n# cox3 %&gt;% \n#   tbl_regression(exp = TRUE)\n\n\nCox proportional hazards regression model is used to analyze the association between covariates and the hazard function (the risk of an event occurring at a specific time) in survival data. The Cox proportional hazards model assumes that the hazard for any individual is proportional to the hazard for any other individual at all time points. This means that the hazard ratio between two groups remains constant over time.\nAlternatively, we can think of the hazard rates obtained from the Cox proportional hazards model represent the estimated instantaneous risk of an event occurring at a particular time. More specifically, the hazard rate at a specific time represents the conditional probability that an event will occur at that time, given that the individual has survived up to that time and has the specific covariate values.\nIn the context of categorical covariates, the hazard rates obtained for different levels of the categorical variable indicate how the risk of the event changes over time compared to the reference group. A hazard rate greater than 1 indicates a higher risk (higher probability of an event occurring) relative to the reference group.\ncivil1:\n\nCoefficient (beta): 0.76\nHazard Ratio (exp(coef)): 2.13\n\nInterpretation: Individuals in the civil1 group have a hazard (risk) of experiencing the event (ending of peacekeeping mission) approximately 2.13 times higher than individuals in the reference group civil0, all other factors being equal. (The coefficient is statistically significant at the 0.05 level)\ninterst1:\n\nCoefficient (beta): -0.87\nHazard Ratio (exp(coef)): 0.42\n\nInterpretation: Individuals in the interst1 group have a hazard (risk) of experiencing the event approximately 0.42 times lower (or 58.2% lower) than individuals in the reference group interst0, all other factors being equal. (The coefficient is statistically significant at the 0.10 level)\n\n\n\n\nCode\ncph_model = CoxPHFitter()\n\ncph_model.fit(r.un_df, \n    duration_col = 'duration', \n    event_col = 'failed', \n    formula = 'civil + interst')\n\n\n&lt;lifelines.CoxPHFitter: fitted with 54 total observations, 15 right-censored observations&gt;\n\n\nCode\nprint(cph_model.summary)\n\n\n               coef  exp(coef)  se(coef)  ...         z         p  -log2(p)\ncovariate                                 ...                              \ncivil      0.756088   2.129929  0.379778  ...  1.990868  0.046495  4.426767\ninterst   -0.872107   0.418070  0.504038  ... -1.730241  0.083587  3.580575\n\n[2 rows x 11 columns]\n\n\n\n\nCode\ncph_model.plot()\nplt.show()\n\n\n\n\n\n\nQuestion 5\n\n\n\n\n\n\nPrompt:\n\n\n\nOf the four estimated models, identify the “best”-fitting model and justify your selection. Produce plots of the survival function and hazard rate based on your chosen model.\n\n\nLet’s pick the model with the lowest AIC:\n\n\nCode\ndata = {\n  \"log Normal\": [round(logn_model.AIC_,2), round(logn_model.BIC_,2)],\n  \"Weibull\": [round(weibull_model.AIC_,2), round(weibull_model.BIC_,2)],\n  \"Gen Gamma\": [round(gg_model.AIC_,2), round(gg_model.BIC_,2)]\n}\n\npy_mod_metric = pd.DataFrame(data, index = [['AIC', 'BIC']]).\\\n    rename_axis(\"Metric\").\\\n    reset_index()\n\n\n\n\nCode\nlibrary(reticulate)\n\npy$py_mod_metric %&gt;% \n  knitr::kable()\n\n\n\n\n\nMetric\nlog Normal\nWeibull\nGen Gamma\n\n\n\n\nAIC\n407.57\n423.97\n404.76\n\n\nBIC\n411.55\n427.95\n404.72"
  },
  {
    "objectID": "posts/peacekeeping_survival/peacekeep.html#consequences-of-an-incorrect-distribution",
    "href": "posts/peacekeeping_survival/peacekeep.html#consequences-of-an-incorrect-distribution",
    "title": "Parametric Survival Analysis: UN Peacekeeping Missions",
    "section": "Consequences of an incorrect distribution",
    "text": "Consequences of an incorrect distribution\n\n\n\n\n\n\nDistributions\n\n\n\nUnderstand the consequences of estimating a parametric survival model with an incorrect distribution.\n\n\nIn short, the suitability of any distribution for your data depends on how well it fits the underlying data-generating process.\nBefore implementing a model, we must give thought to the data generating process or the underlying mechanism or model that generates the observed data. We represent these processes through distributions–and the respective distributional parameters. Using an incorrect parametric distribution (Weibull for instance) when the true distribution is Gamma can result in biased parameter estimates, poor model fit, and inaccurate survival predictions (among other things) because the respective distribution parameters (shape and scale) are significantly different."
  },
  {
    "objectID": "posts/peacekeeping_survival/peacekeep.html#monotonic-and-non-monotonic-distributions",
    "href": "posts/peacekeeping_survival/peacekeep.html#monotonic-and-non-monotonic-distributions",
    "title": "Parametric Survival Analysis: UN Peacekeeping Missions",
    "section": "Monotonic and non-monotonic distributions",
    "text": "Monotonic and non-monotonic distributions\n\n\n\n\n\n\nPrompt:\n\n\n\nHere I choose one monotonic distribution and one non-monotonic distribution and estimate additional parametric survival models and interpret the results.\n\n\n\nR SolutionPython Solution\n\n\nMonotonic Distribution\n\n\nCode\n## Estimate parametric models - Generalized gamma\n\nmonot_fit &lt;- flexsurvreg(\n  formula = \n    Surv(time = duration,\n         event = failed) ~ wartype,\n  data = un_df_cat,\n  dist = \"weibull\"\n  )\n\nmonot_fit \n\n\nCall:\nflexsurvreg(formula = Surv(time = duration, event = failed) ~ \n    wartype, data = un_df_cat, dist = \"weibull\")\n\nEstimates: \n                data mean  est       L95%      U95%      se        exp(est)\nshape                 NA     0.8069    0.6331    1.0285    0.0999        NA\nscale                 NA    72.8156   43.2961  122.4616   19.3139        NA\nwartypecivil      0.2593    -1.1004   -1.9741   -0.2267    0.4458    0.3327\nwartypeinterst    0.1852     1.7368    0.5284    2.9452    0.6165    5.6793\n                L95%      U95%    \nshape                 NA        NA\nscale                 NA        NA\nwartypecivil      0.1389    0.7972\nwartypeinterst    1.6963   19.0152\n\nN = 54,  Events: 39,  Censored: 15\nTotal time at risk: 3994\nLog-likelihood = -201.1528, df = 4\nAIC = 410.3055\n\n\nNon-Monotonic Distribution\n\n\nCode\n## Estimate parametric models - Generalized gamma\n\nnon_mono_fit &lt;- flexsurvreg(\n  formula = \n    Surv(time = duration,\n         event = failed) ~ wartype,\n  data = un_df_cat,\n  dist = \"lognormal\"\n  )\n\nnon_mono_fit \n\n\nCall:\nflexsurvreg(formula = Surv(time = duration, event = failed) ~ \n    wartype, data = un_df_cat, dist = \"lognormal\")\n\nEstimates: \n                data mean  est     L95%    U95%    se      exp(est)  L95%  \nmeanlog             NA      3.592   3.081   4.103   0.261      NA        NA\nsdlog               NA      1.365   1.080   1.724   0.163      NA        NA\nwartypecivil     0.259     -0.590  -1.483   0.304   0.456   0.555     0.227\nwartypeinterst   0.185      1.385   0.319   2.451   0.544   3.995     1.376\n                U95%  \nmeanlog             NA\nsdlog               NA\nwartypecivil     1.355\nwartypeinterst  11.597\n\nN = 54,  Events: 39,  Censored: 15\nTotal time at risk: 3994\nLog-likelihood = -196.7765, df = 4\nAIC = 401.5531\n\n\n\n\nWeibull Distribution\n\n\nCode\nweibull_model = WeibullFitter().\\\n    fit(r.un_df_num['duration'], event_observed = r.un_df_num['failed'])\n\nprint(weibull_model.summary)\n\n\n              coef   se(coef)  coef lower 95%  ...         z         p   -log2(p)\nlambda_  87.564550  22.050354       44.346651  ...  3.925767  0.000086  13.497710\nrho_      0.636418   0.076044        0.487374  ... -4.781193  0.000002  19.130345\n\n[2 rows x 8 columns]\n\n\n\n\nCode\n# weibull_model.plot()\nweibull_model.plot()\nplt.show();\n\n\n\n\n\n\n\nCode\n# create an exponential model\nlogn_model = LogNormalFitter().\\\n    fit(r.un_df['duration'], event_observed = r.un_df['failed'])\n\nprint(logn_model.summary)\n\n\n            coef  se(coef)  coef lower 95%  ...          z             p    -log2(p)\nmu_     3.710521  0.220683        3.277989  ...  16.813784  1.934223e-63  208.329716\nsigma_  1.527447  0.182320        1.170107  ...   2.892978  3.816083e-03    8.033692\n\n[2 rows x 8 columns]\n\n\n\n\nCode\nlogn_model.plot()\nplt.show();"
  }
]